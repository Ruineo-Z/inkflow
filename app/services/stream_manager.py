"""
æµå¼ç”Ÿæˆç®¡ç†å™¨

è´Ÿè´£åè°ƒRedisç¼“å­˜å’ŒPostgreSQLæŒä¹…åŒ–:
- å®æ—¶å†™å…¥Redis(æ¯ä¸ªchunk)
- å®šæ—¶åŒæ­¥PostgreSQL(æ¯5ç§’)
- ç”Ÿæˆå®Œæˆæ—¶æœ€ç»ˆå†™å…¥PostgreSQLå¹¶æ¸…ç†Redis
- ä»Redisæµå¼æ¨é€ç»™å‰ç«¯(æ”¯æŒæ–­çº¿é‡è¿)

è®¾è®¡åŸåˆ™:
- Redisæ‰¿è½½99%çš„å†™å…¥å‹åŠ›
- PostgreSQLæ¯5ç§’æ‰¹é‡æ›´æ–°(ä¸­é—´çŠ¶æ€)
- å¼‚å¸¸æ—¶è®©é”™è¯¯è‡ªç„¶æŠ›å‡º,ç”±ä¸Šå±‚ç»Ÿä¸€å¤„ç†
- æ‰€æœ‰å®¢æˆ·ç«¯ç»Ÿä¸€ä»Redisè·å–æ•°æ®(æ–°ç”Ÿæˆå’Œé‡è¿éƒ½æ˜¯åŒä¸€ä¸ªæ¥å£)
"""
import asyncio
import logging
import uuid
import json
from datetime import datetime
from typing import AsyncGenerator, Optional
from contextlib import asynccontextmanager

import redis.asyncio as redis
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.services.chapter_cache import ChapterCacheService
from app.services.chapter import ChapterService
from app.models.chapter import Chapter, ChapterStatus

logger = logging.getLogger(__name__)


class StreamGenerationManager:
    """æµå¼ç”Ÿæˆç®¡ç†å™¨ - åè°ƒRediså’ŒPostgreSQLçš„æ•°æ®æµè½¬"""

    SYNC_INTERVAL = 5  # PostgreSQLåŒæ­¥é—´éš”(ç§’)

    def __init__(
        self,
        chapter_id: int,
        novel_id: int,
        session_id: str,
        db: AsyncSession
    ):
        """
        åˆå§‹åŒ–æµå¼ç”Ÿæˆç®¡ç†å™¨

        Args:
            chapter_id: ç« èŠ‚ID
            novel_id: å°è¯´ID
            session_id: ç”Ÿæˆä¼šè¯ID
            db: æ•°æ®åº“ä¼šè¯
        """
        self.chapter_id = chapter_id
        self.novel_id = novel_id
        self.session_id = session_id
        self.db = db

        # å†…å®¹ç´¯ç§¯å™¨
        self.title: str = ""
        self.content_buffer: str = ""
        self.content_length: int = 0

        # åŒæ­¥æ§åˆ¶
        self._last_sync_time: float = 0
        self._sync_task: Optional[asyncio.Task] = None
        self._generation_started: bool = False

    async def start_generation(self, title: str) -> None:
        """
        å¼€å§‹ç”Ÿæˆæµç¨‹

        Args:
            title: ç« èŠ‚æ ‡é¢˜

        Raises:
            redis.RedisError: Redisæ“ä½œå¤±è´¥
        """
        self.title = title
        self._generation_started = True

        # åœ¨Redisä¸­åˆå§‹åŒ–generatingæ•°æ® (Phase 2: åªå­˜å‰ç«¯å±•ç¤ºå­—æ®µ)
        await ChapterCacheService.set_generating_content(
            chapter_id=self.chapter_id,
            title=self.title,
            content=""
        )

        # æ›´æ–°æ•°æ®åº“ä¸­çš„ç« èŠ‚çŠ¶æ€å’Œtitle
        chapter_service = ChapterService(self.db)

        # å…ˆæ›´æ–°title
        result = await self.db.execute(
            select(Chapter).where(Chapter.id == self.chapter_id)
        )
        chapter = result.scalar_one_or_none()
        if chapter:
            chapter.title = title
            await self.db.commit()

        # å†æ›´æ–°çŠ¶æ€
        await chapter_service.update_chapter_status(
            self.chapter_id,
            ChapterStatus.GENERATING,
            session_id=self.session_id,
            generation_started_at=datetime.now()
        )

        logger.info(f"âœ… ç« èŠ‚ {self.chapter_id} å¼€å§‹ç”Ÿæˆ: {title}")

    async def append_chunk(self, chunk: str) -> None:
        """
        è¿½åŠ å†…å®¹chunk

        Args:
            chunk: æ–°ç”Ÿæˆçš„å†…å®¹ç‰‡æ®µ

        Raises:
            redis.RedisError: Rediså†™å…¥å¤±è´¥
        """
        if not self._generation_started:
            raise RuntimeError("Generation not started. Call start_generation() first.")

        self.content_buffer += chunk
        self.content_length += len(chunk)

        # å®æ—¶å†™å…¥Redis (Phase 2: åªå­˜å‰ç«¯å±•ç¤ºå­—æ®µ)
        await ChapterCacheService.set_generating_content(
            chapter_id=self.chapter_id,
            title=self.title,
            content=self.content_buffer
        )

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŒæ­¥PostgreSQL
        current_time = asyncio.get_event_loop().time()
        if current_time - self._last_sync_time >= self.SYNC_INTERVAL:
            await self._sync_to_postgresql()
            self._last_sync_time = current_time

    async def _sync_to_postgresql(self) -> None:
        """
        åŒæ­¥å½“å‰å†…å®¹åˆ°PostgreSQL(ä¸­é—´çŠ¶æ€)

        Raises:
            SQLAlchemy exceptions: æ•°æ®åº“æ“ä½œå¤±è´¥
        """
        try:
            chapter_service = ChapterService(self.db)
            await chapter_service.update_chapter_content(
                chapter_id=self.chapter_id,
                content=self.content_buffer,
                content_length=self.content_length
            )
            await self.db.commit()

            logger.info(f"ğŸ”„ ç« èŠ‚ {self.chapter_id} åŒæ­¥åˆ°PostgreSQL: {self.content_length} å­—ç¬¦")
        except Exception as e:
            logger.error(f"âŒ PostgreSQLåŒæ­¥å¤±è´¥ {self.chapter_id}: {e}")
            # ä¸é˜»æ–­ç”Ÿæˆæµç¨‹,ç»§ç»­ä¾èµ–Redis
            # è®©é”™è¯¯æŠ›å‡º,ç”±ä¸Šå±‚å†³å®šå¦‚ä½•å¤„ç†
            raise

    async def complete_generation(
        self,
        final_content: str,
        options: list,
        summary: str = None
    ) -> None:
        """
        å®Œæˆç”Ÿæˆ,æœ€ç»ˆå†™å…¥PostgreSQLå¹¶æ¸…ç†Redis

        Args:
            final_content: å®Œæ•´ç« èŠ‚å†…å®¹
            options: ç« èŠ‚é€‰é¡¹åˆ—è¡¨
            summary: ç« èŠ‚æ‘˜è¦(å¯é€‰)

        Raises:
            redis.RedisError: Redisæ“ä½œå¤±è´¥
            SQLAlchemy exceptions: æ•°æ®åº“æ“ä½œå¤±è´¥
        """
        if not self._generation_started:
            raise RuntimeError("Generation not started.")

        # æ›´æ–°å†…å®¹
        self.content_buffer = final_content
        self.content_length = len(final_content)

        # 1. æœ€ç»ˆå†™å…¥PostgreSQL
        chapter_service = ChapterService(self.db)

        # æ›´æ–°å†…å®¹å’Œsummary
        result = await self.db.execute(
            select(Chapter).where(Chapter.id == self.chapter_id)
        )
        chapter = result.scalar_one_or_none()
        if chapter:
            chapter.content = final_content
            chapter.content_length = self.content_length
            if summary:
                chapter.summary = summary
            await self.db.commit()

        # 2. åˆ›å»ºé€‰é¡¹
        await chapter_service.create_chapter_options(
            chapter_id=self.chapter_id,
            options_data=options
        )

        # 3. æ›´æ–°çŠ¶æ€ä¸ºcompleted
        await chapter_service.update_chapter_status(
            self.chapter_id,
            ChapterStatus.COMPLETED,
            generation_completed_at=datetime.now()
        )

        await self.db.commit()

        # 4. æ¸…ç†Redis generatingæ•°æ® (Phase 2: ç”Ÿæˆå®Œæˆæ—¶åˆ é™¤)
        await ChapterCacheService.delete_generating_content(self.chapter_id)

        logger.info(f"âœ… ç« èŠ‚ {self.chapter_id} ç”Ÿæˆå®Œæˆ: {self.content_length} å­—ç¬¦, {len(options)} ä¸ªé€‰é¡¹")

    async def fail_generation(self, error_message: str) -> None:
        """
        æ ‡è®°ç”Ÿæˆå¤±è´¥

        Args:
            error_message: é”™è¯¯ä¿¡æ¯

        Raises:
            redis.RedisError: Redisæ“ä½œå¤±è´¥
        """
        if not self._generation_started:
            return

        # 1. æ›´æ–°æ•°æ®åº“çŠ¶æ€
        try:
            chapter_service = ChapterService(self.db)
            await chapter_service.update_chapter_status(
                self.chapter_id,
                ChapterStatus.FAILED
            )
            await self.db.commit()
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°å¤±è´¥çŠ¶æ€åˆ°æ•°æ®åº“å¤±è´¥ {self.chapter_id}: {e}")

        # 2. æ¸…ç†Redisæ•°æ® (Phase 2: ç”Ÿæˆå¤±è´¥æ—¶åˆ é™¤)
        await ChapterCacheService.delete_generating_content(self.chapter_id)

        logger.warning(f"âš ï¸  ç« èŠ‚ {self.chapter_id} ç”Ÿæˆå¤±è´¥: {error_message}")

    @classmethod
    def generate_session_id(cls) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID"""
        return str(uuid.uuid4())

    @staticmethod
    async def stream_to_client(
        chapter_id: int,
        db: AsyncSession
    ) -> AsyncGenerator[str, None]:
        """
        ä»Redisæµå¼æ¨é€ç« èŠ‚æ•°æ®ç»™å‰ç«¯ï¼ˆç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒæ–°ç”Ÿæˆå’Œæ–­çº¿é‡è¿ï¼‰

        é€»è¾‘ï¼š
        1. æ£€æŸ¥ç« èŠ‚çŠ¶æ€
        2. å¦‚æœæ­£åœ¨ç”Ÿæˆæˆ–å·²å®Œæˆï¼šä»Redisè¯»å–å¹¶æµå¼æ¨é€
        3. æ¯100msè½®è¯¢ä¸€æ¬¡Redisï¼Œæ¨é€å¢é‡å†…å®¹
        4. ç”Ÿæˆå®Œæˆæ—¶æ¨é€completeäº‹ä»¶å¹¶é€€å‡º

        Args:
            chapter_id: ç« èŠ‚ID
            db: æ•°æ®åº“ä¼šè¯

        Yields:
            SSEæ ¼å¼çš„äº‹ä»¶å­—ç¬¦ä¸²

        Raises:
            ValueError: ç« èŠ‚ä¸å­˜åœ¨æˆ–çŠ¶æ€å¼‚å¸¸
        """
        # 1. æŸ¥è¯¢ç« èŠ‚çŠ¶æ€
        chapter_service = ChapterService(db)
        chapter = await chapter_service.get_chapter_by_id(chapter_id)

        if not chapter:
            raise ValueError(f"ç« èŠ‚ {chapter_id} ä¸å­˜åœ¨")

        # 2. æ£€æŸ¥ç« èŠ‚çŠ¶æ€
        if chapter.status == ChapterStatus.FAILED:
            # ç”Ÿæˆå¤±è´¥ï¼Œå‘é€erroräº‹ä»¶
            yield f"event: error\ndata: {json.dumps({'error': 'ç« èŠ‚ç”Ÿæˆå¤±è´¥'}, ensure_ascii=False)}\n\n"
            return

        elif chapter.status == ChapterStatus.COMPLETED:
            # å·²å®Œæˆï¼Œç›´æ¥æ¨é€å®Œæ•´æ•°æ®
            # åŠ è½½optionså…³ç³»
            await db.refresh(chapter, ["options"])
            complete_data = {
                "chapter_id": chapter.id,
                "title": chapter.title,
                "content": chapter.content,
                "options": [
                    {
                        "id": opt.id,
                        "text": opt.option_text,
                        "impact_hint": opt.impact_description
                    }
                    for opt in chapter.options
                ]
            }
            yield f"event: complete\ndata: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
            return

        elif chapter.status != ChapterStatus.GENERATING:
            raise ValueError(f"ç« èŠ‚ {chapter_id} çŠ¶æ€å¼‚å¸¸: {chapter.status}")

        # 3. æ­£åœ¨ç”Ÿæˆï¼Œä»Redisæµå¼æ¨é€
        redis_key = f"chapter:{chapter_id}:generating"
        last_content_length = 0
        no_update_count = 0
        title_sent = False  # æ ‡å¿—ä½:titleæ˜¯å¦å·²æ¨é€
        MAX_NO_UPDATE = 600  # 60ç§’æ— æ›´æ–°è§†ä¸ºè¶…æ—¶ï¼ˆ600 * 100msï¼‰- AIç”Ÿæˆéœ€è¦æ—¶é—´

        logger.info(f"ğŸ“¡ å¼€å§‹æµå¼æ¨é€ç« èŠ‚ {chapter_id}")

        while True:
            try:
                # è¯»å–Redisæ•°æ®
                data_str = await ChapterCacheService.get_generating_content(chapter_id)

                if data_str:
                    data = json.loads(data_str) if isinstance(data_str, str) else data_str
                    current_title = data.get('title', '')
                    current_content = data.get('content', '')
                    current_length = len(current_content)

                    # é¦–æ¬¡æ¨é€title(åªæ¨é€ä¸€æ¬¡)
                    if current_title and not title_sent:
                        yield f"event: summary\ndata: {json.dumps({'title': current_title}, ensure_ascii=False)}\n\n"
                        title_sent = True

                    # æ¨é€å¢é‡content
                    if current_length > last_content_length:
                        incremental = current_content[last_content_length:]
                        last_content_length = current_length
                        no_update_count = 0  # é‡ç½®æ— æ›´æ–°è®¡æ•°

                        yield f"event: content\ndata: {json.dumps({'text': incremental}, ensure_ascii=False)}\n\n"

                        logger.debug(f"ğŸ“¤ æ¨é€å¢é‡: {len(incremental)} å­—ç¬¦, æ€»è®¡: {current_length}")
                    else:
                        no_update_count += 1

                # æ£€æŸ¥ç« èŠ‚çŠ¶æ€æ˜¯å¦å˜åŒ–
                await db.refresh(chapter)

                if chapter.status == ChapterStatus.COMPLETED:
                    # ç”Ÿæˆå®Œæˆ
                    logger.info(f"âœ… ç« èŠ‚ {chapter_id} ç”Ÿæˆå®Œæˆï¼Œæ¨é€completeäº‹ä»¶")

                    # åŠ è½½optionså…³ç³»
                    await db.refresh(chapter, ["options"])
                    complete_data = {
                        "chapter_id": chapter.id,
                        "title": chapter.title,
                        "content": chapter.content,
                        "options": [
                            {
                                "id": opt.id,
                                "text": opt.option_text,
                                "impact_hint": opt.impact_description
                            }
                            for opt in chapter.options
                        ]
                    }
                    yield f"event: complete\ndata: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
                    break

                elif chapter.status == ChapterStatus.FAILED:
                    # ç”Ÿæˆå¤±è´¥
                    logger.warning(f"âš ï¸  ç« èŠ‚ {chapter_id} ç”Ÿæˆå¤±è´¥")
                    yield f"event: error\ndata: {json.dumps({'error': 'ç« èŠ‚ç”Ÿæˆå¤±è´¥'}, ensure_ascii=False)}\n\n"
                    break

                # è¶…æ—¶æ£€æµ‹
                if no_update_count >= MAX_NO_UPDATE:
                    logger.warning(f"âš ï¸  ç« èŠ‚ {chapter_id} è¶…æ—¶ï¼ˆ10ç§’æ— æ›´æ–°ï¼‰")
                    yield f"event: error\ndata: {json.dumps({'error': 'ç”Ÿæˆè¶…æ—¶'}, ensure_ascii=False)}\n\n"
                    break

                # ç­‰å¾…100ms
                await asyncio.sleep(0.1)

            except Exception as e:
                logger.error(f"âŒ æµå¼æ¨é€å‡ºé”™ {chapter_id}: {e}")
                yield f"event: error\ndata: {json.dumps({'error': str(e)}, ensure_ascii=False)}\n\n"
                break

        logger.info(f"ğŸ“¡ ç« èŠ‚ {chapter_id} æµå¼æ¨é€ç»“æŸ")


@asynccontextmanager
async def managed_stream_generation(
    chapter_id: int,
    novel_id: int,
    session_id: str,
    db: AsyncSession
) -> AsyncGenerator[StreamGenerationManager, None]:
    """
    æµå¼ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨(ç¡®ä¿å¼‚å¸¸æ—¶æ­£ç¡®æ¸…ç†)

    Usage:
        async with managed_stream_generation(...) as manager:
            await manager.start_generation(title)
            await manager.append_chunk(chunk)
            await manager.complete_generation(content, options)

    Raises:
        å¼‚å¸¸ä¼šè‡ªåŠ¨è°ƒç”¨fail_generationå¹¶é‡æ–°æŠ›å‡º
    """
    manager = StreamGenerationManager(chapter_id, novel_id, session_id, db)

    try:
        yield manager
    except Exception as e:
        # å¼‚å¸¸æ—¶æ ‡è®°å¤±è´¥
        try:
            await manager.fail_generation(str(e))
        except Exception as cleanup_error:
            logger.error(f"âŒ æ¸…ç†å¤±è´¥çŠ¶æ€æ—¶å‡ºé”™: {cleanup_error}")

        # é‡æ–°æŠ›å‡ºåŸå§‹å¼‚å¸¸
        raise