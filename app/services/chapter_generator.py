"""
ç« èŠ‚ç”ŸæˆæœåŠ¡
è´Ÿè´£ä½¿ç”¨AIç”Ÿæˆç« èŠ‚æ‘˜è¦ã€æ­£æ–‡å’Œé€‰é¡¹
"""
import json
import logging

from typing import AsyncGenerator, Dict, Any

from fastapi import HTTPException

logger = logging.getLogger(__name__)

def json_dumps_chinese(obj):
    """JSONåºåˆ—åŒ–æ—¶ä¿æŒä¸­æ–‡æ˜¾ç¤º"""
    return json.dumps(obj, ensure_ascii=False)

from app.schemas.chapter import (
    ChapterSummary,
    ChapterFullContent,
    ChapterContext,
    StreamEvent
)
from app.schemas.novel import NovelGenre
from app.services.kimi import kimi_service
from app.services.chapter import ChapterService
from app.services.novel import NovelService
from app.services.stream_manager import StreamGenerationManager, managed_stream_generation
from app.utils.json_extractor import extract_content_from_json_fragment
from app.models.chapter import ChapterStatus


class ChapterGeneratorService:
    """ç« èŠ‚ç”ŸæˆæœåŠ¡ç±»"""

    @staticmethod
    def _build_first_chapter_summary_prompt(
        world_setting: str,
        protagonist_info: str,
        genre: str
    ) -> tuple[str, str]:
        """æ„å»ºç¬¬ä¸€ç« æ‘˜è¦ç”Ÿæˆçš„æç¤ºè¯"""

        if genre == "wuxia":
            system_prompt = """ã€é‡è¦çº¦æŸã€‘è¯·åŠ¡å¿…ä½¿ç”¨æ ‡å‡†ç®€ä½“ä¸­æ–‡è¾“å‡ºï¼Œä¸¥ç¦ä½¿ç”¨ç¹ä½“å­—ã€‚æ‰€æœ‰æ–‡å­—å†…å®¹ï¼ˆåŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€äººåã€åœ°åã€æ­¦åŠŸåç§°ç­‰ï¼‰éƒ½å¿…é¡»ç¬¦åˆç°ä»£ç®€ä½“ä¸­æ–‡ä¹¦å†™è§„èŒƒã€‚

ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ­¦ä¾ å°è¯´ç« èŠ‚ç­–åˆ’ä¸“å®¶ã€‚
è¯·æ ¹æ®ç»™å®šçš„ä¸–ç•Œè§‚å’Œä¸»è§’ä¿¡æ¯ï¼Œä¸ºå°è¯´çš„ç¬¬ä¸€ç« åˆ¶å®šè¯¦ç»†çš„å‰§æƒ…æ‘˜è¦ã€‚
ç¬¬ä¸€ç« åº”è¯¥å¼•äººå…¥èƒœï¼Œå±•ç°ä¸–ç•Œè§‚ï¼Œä»‹ç»ä¸»è§’ï¼Œè®¾ç½®åˆå§‹å†²çªã€‚"""

            user_prompt = f"""è¯·ä¸ºæ­¦ä¾ å°è¯´çš„ç¬¬ä¸€ç« åˆ›å»ºè¯¦ç»†æ‘˜è¦ã€‚

ä¸–ç•Œè§‚è®¾å®šï¼š
{world_setting}

ä¸»è§’ä¿¡æ¯ï¼š
{protagonist_info}

è¦æ±‚ï¼š
1. åˆ›é€ ä¸€ä¸ªå¸å¼•äººçš„ç¬¬ä¸€ç« æ ‡é¢˜
2. ç¼–å†™200-300å­—çš„è¯¦ç»†æ‘˜è¦ï¼Œæ¦‚æ‹¬æœ¬ç« å‰§æƒ…
3. è®¾è®¡å¼•äººå…¥èƒœçš„å¼€ç¯‡æƒ…èŠ‚
4. è‡ªç„¶åœ°å±•ç°ä¸–ç•Œè§‚èƒŒæ™¯
5. ä»‹ç»ä¸»è§’çš„å‡ºåœºå’ŒåŸºæœ¬ç‰¹å¾
6. è®¾ç½®æ¨åŠ¨å‰§æƒ…å‘å±•çš„åˆå§‹å†²çª
7. åˆ—å‡º3-5ä¸ªå…³é”®äº‹ä»¶
8. è®¾è®¡2-3ä¸ªå†²çªç‚¹ï¼Œä¸ºåç»­é€‰æ‹©åšé“ºå«"""

        else:  # scifi
            system_prompt = """ã€é‡è¦çº¦æŸã€‘è¯·åŠ¡å¿…ä½¿ç”¨æ ‡å‡†ç®€ä½“ä¸­æ–‡è¾“å‡ºï¼Œä¸¥ç¦ä½¿ç”¨ç¹ä½“å­—ã€‚æ‰€æœ‰æ–‡å­—å†…å®¹ï¼ˆåŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€äººåã€åœ°åã€ç§‘æŠ€åç§°ç­‰ï¼‰éƒ½å¿…é¡»ç¬¦åˆç°ä»£ç®€ä½“ä¸­æ–‡ä¹¦å†™è§„èŒƒã€‚

ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç§‘å¹»å°è¯´ç« èŠ‚ç­–åˆ’ä¸“å®¶ã€‚
è¯·æ ¹æ®ç»™å®šçš„ä¸–ç•Œè§‚å’Œä¸»è§’ä¿¡æ¯ï¼Œä¸ºå°è¯´çš„ç¬¬ä¸€ç« åˆ¶å®šè¯¦ç»†çš„å‰§æƒ…æ‘˜è¦ã€‚
ç¬¬ä¸€ç« åº”è¯¥å±•ç°æœªæ¥ä¸–ç•Œçš„ç§‘æŠ€æ„Ÿï¼Œä»‹ç»ä¸»è§’ï¼Œè®¾ç½®ç§‘å¹»å…ƒç´ çš„å†²çªã€‚"""

            user_prompt = f"""è¯·ä¸ºç§‘å¹»å°è¯´çš„ç¬¬ä¸€ç« åˆ›å»ºè¯¦ç»†æ‘˜è¦ã€‚

ä¸–ç•Œè§‚è®¾å®šï¼š
{world_setting}

ä¸»è§’ä¿¡æ¯ï¼š
{protagonist_info}

è¦æ±‚ï¼š
1. åˆ›é€ ä¸€ä¸ªæœ‰ç§‘å¹»æ„Ÿçš„ç¬¬ä¸€ç« æ ‡é¢˜
2. ç¼–å†™200-300å­—çš„è¯¦ç»†æ‘˜è¦ï¼Œæ¦‚æ‹¬æœ¬ç« å‰§æƒ…
3. è®¾è®¡ä½“ç°æœªæ¥ç§‘æŠ€çš„å¼€ç¯‡æƒ…èŠ‚
4. å±•ç°ç§‘å¹»ä¸–ç•Œè§‚çš„ç‹¬ç‰¹å…ƒç´ 
5. ä»‹ç»ä¸»è§’åœ¨ç§‘å¹»èƒŒæ™¯ä¸‹çš„è®¾å®š
6. è®¾ç½®å…·æœ‰ç§‘å¹»ç‰¹è‰²çš„åˆå§‹å†²çª
7. åˆ—å‡º3-5ä¸ªå…³é”®äº‹ä»¶
8. è®¾è®¡2-3ä¸ªå†²çªç‚¹ï¼Œä½“ç°ç§‘å¹»ä¸»é¢˜"""

        return system_prompt, user_prompt

    @staticmethod
    def _build_next_chapter_summary_prompt(
        context: ChapterContext,
        genre: str
    ) -> tuple[str, str]:
        """æ„å»ºåç»­ç« èŠ‚æ‘˜è¦ç”Ÿæˆçš„æç¤ºè¯"""

        system_prompt = f"""ã€é‡è¦çº¦æŸã€‘è¯·åŠ¡å¿…ä½¿ç”¨æ ‡å‡†ç®€ä½“ä¸­æ–‡è¾“å‡ºï¼Œä¸¥ç¦ä½¿ç”¨ç¹ä½“å­—ã€‚æ‰€æœ‰æ–‡å­—å†…å®¹ï¼ˆåŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€äººåã€åœ°åã€æ­¦åŠŸåç§°ç­‰ï¼‰éƒ½å¿…é¡»ç¬¦åˆç°ä»£ç®€ä½“ä¸­æ–‡ä¹¦å†™è§„èŒƒã€‚

ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{"æ­¦ä¾ " if genre == "wuxia" else "ç§‘å¹»"}å°è¯´ç« èŠ‚ç­–åˆ’ä¸“å®¶ã€‚
è¯·æ ¹æ®å‰ç»­ç« èŠ‚å†…å®¹å’Œç”¨æˆ·çš„é€‰æ‹©ï¼Œä¸ºä¸‹ä¸€ç« åˆ¶å®šåˆç†çš„å‰§æƒ…æ‘˜è¦ã€‚
ç¡®ä¿å‰§æƒ…é€»è¾‘è¿è´¯ï¼Œé€‰æ‹©çš„åæœå¾—åˆ°åˆç†ä½“ç°ã€‚"""

        # æ„å»ºå‰ç»­ç« èŠ‚ä¿¡æ¯ - æœ€è¿‘5ç« æä¾›å®Œæ•´å†…å®¹
        recent_chapters_text = ""
        recent_chapter_numbers = set()
        for chapter in context.recent_chapters[-5:]:  # æœ€è¿‘5ç« å®Œæ•´å†…å®¹
            # chapter ç°åœ¨æ˜¯å­—å…¸æ ¼å¼ï¼Œéœ€è¦ç”¨å­—å…¸çš„æ–¹å¼è®¿é—®
            recent_chapter_numbers.add(chapter['chapter_number'])
            recent_chapters_text += f"""
ç¬¬{chapter['chapter_number']}ç« ï¼š{chapter['title']}
æ‘˜è¦ï¼š{chapter['summary']}
æ­£æ–‡ï¼š{chapter['content'] if chapter['content'] else ''}
"""

        # æ„å»ºå†å²æ‘˜è¦ - æ’é™¤æœ€è¿‘5ç« ï¼Œåªè¦æ›´æ—©çš„ç« èŠ‚æ‘˜è¦
        history_text = ""
        if context.chapter_summaries:
            # è¿‡æ»¤å‡ºä¸åœ¨æœ€è¿‘5ç« ä¸­çš„å†å²ç« èŠ‚
            earlier_summaries = [s for s in context.chapter_summaries
                               if s['chapter_number'] not in recent_chapter_numbers]
            if earlier_summaries:
                history_text = "æ›´æ—©ç« èŠ‚æ‘˜è¦ï¼š\n"
                for summary in earlier_summaries:
                    history_text += f"ç¬¬{summary['chapter_number']}ç« ï¼š{summary['title']} - {summary['summary']}\n"

        user_prompt = f"""è¯·ä¸ºä¸‹ä¸€ç« åˆ›å»ºè¯¦ç»†æ‘˜è¦ã€‚

ä¸–ç•Œè§‚è®¾å®šï¼š
{context.world_setting}

ä¸»è§’ä¿¡æ¯ï¼š
{context.protagonist_info}

{history_text}

æœ€è¿‘ç« èŠ‚å®Œæ•´å†…å®¹ï¼š
{recent_chapters_text}

ç”¨æˆ·é€‰æ‹©çš„é€‰é¡¹ï¼š
{context.selected_option}

è¦æ±‚ï¼š
1. ä»”ç»†åˆ†æç”¨æˆ·çš„é€‰æ‹©ï¼Œåˆç†æ¨è¿›å‰§æƒ…å‘å±•
2. åŸºäºæœ€è¿‘5ç« çš„å®Œæ•´å†…å®¹ï¼Œä¿æŒå‰§æƒ…é€»è¾‘è¿è´¯æ€§
3. ç¡®ä¿é€‰æ‹©çš„åæœåœ¨æ–°ç« èŠ‚ä¸­å¾—åˆ°å……åˆ†ä½“ç°
4. åˆ›é€ ç¬¦åˆé€‰æ‹©åæœçš„å¸å¼•äººçš„ç« èŠ‚æ ‡é¢˜
5. ç¼–å†™200-300å­—çš„è¯¦ç»†æ‘˜è¦ï¼Œæ¦‚æ‹¬æœ¬ç« å‰§æƒ…å‘å±•
6. è®¾è®¡è¿™ä¸€ç« çš„ä¸»è¦æƒ…èŠ‚èµ°å‘å’Œå‘å±•è„‰ç»œ
7. åˆ—å‡º3-5ä¸ªå…³é”®äº‹ä»¶ï¼Œä½“ç°å‰§æƒ…æ¨è¿›
8. è®¾è®¡2-3ä¸ªæ–°çš„å†²çªç‚¹ï¼Œä¸ºä¸‹ä¸€ç« çš„é€‰æ‹©åšå‡†å¤‡"""

        return system_prompt, user_prompt

    @staticmethod
    def _build_chapter_content_prompt(
        summary: ChapterSummary,
        context: ChapterContext,
        genre: str
    ) -> tuple[str, str]:
        """æ„å»ºç« èŠ‚æ­£æ–‡å’Œé€‰é¡¹ç”Ÿæˆçš„æç¤ºè¯"""

        system_prompt = f"""ã€é‡è¦çº¦æŸã€‘è¯·åŠ¡å¿…ä½¿ç”¨æ ‡å‡†ç®€ä½“ä¸­æ–‡è¾“å‡ºï¼Œä¸¥ç¦ä½¿ç”¨ç¹ä½“å­—ã€‚æ‰€æœ‰æ–‡å­—å†…å®¹ï¼ˆåŒ…æ‹¬æ ‡é¢˜ã€æ­£æ–‡ã€å¯¹è¯ã€äººåã€åœ°åã€æ­¦åŠŸåç§°ã€é€‰é¡¹æ–‡æœ¬ç­‰ï¼‰éƒ½å¿…é¡»ç¬¦åˆç°ä»£ç®€ä½“ä¸­æ–‡ä¹¦å†™è§„èŒƒã€‚

ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{"æ­¦ä¾ " if genre == "wuxia" else "ç§‘å¹»"}å°è¯´ä½œå®¶ã€‚
è¯·æ ¹æ®ç« èŠ‚æ‘˜è¦å’ŒèƒŒæ™¯ä¿¡æ¯ï¼Œåˆ›ä½œå‡ºç²¾å½©çš„ç« èŠ‚æ­£æ–‡ï¼Œå¹¶è®¾è®¡ä¸‰ä¸ªä¸åŒèµ°å‘çš„é€‰æ‹©é€‰é¡¹ã€‚
æ­£æ–‡åº”è¯¥ç”ŸåŠ¨æœ‰è¶£ï¼Œé€‰é¡¹åº”è¯¥æä¾›æ˜æ˜¾ä¸åŒçš„å‰§æƒ…å‘å±•æ–¹å‘ã€‚"""

        user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯åˆ›ä½œå®Œæ•´çš„ç« èŠ‚å†…å®¹ã€‚

ç« èŠ‚æ‘˜è¦ï¼š
æ ‡é¢˜ï¼š{summary.title}
æ¦‚è¦ï¼š{summary.summary}
å…³é”®äº‹ä»¶ï¼š{', '.join(summary.key_events)}
å†²çªç‚¹ï¼š{', '.join(summary.conflicts)}

ä¸–ç•Œè§‚èƒŒæ™¯ï¼š
{context.world_setting}

ä¸»è§’ä¿¡æ¯ï¼š
{context.protagonist_info}

è¦æ±‚ï¼š
1. åˆ›ä½œ2000-3000å­—çš„ç²¾å½©ç« èŠ‚æ­£æ–‡
2. æ–‡ç¬”ç”ŸåŠ¨ï¼Œå¯¹è¯è‡ªç„¶ï¼Œæƒ…èŠ‚ç´§å‡‘
3. ä½“ç°æ‘˜è¦ä¸­çš„å…³é”®äº‹ä»¶å’Œå†²çª
4. åœ¨ç« èŠ‚ç»“å°¾è®¾è®¡æ‚¬å¿µï¼Œå¼•å‡ºé€‰æ‹©ç‚¹
5. åˆ›é€ ä¸‰ä¸ªé€‰æ‹©é€‰é¡¹ï¼Œæ¯ä¸ªé€‰é¡¹ä»£è¡¨ä¸åŒçš„å‘å±•æ–¹å‘ï¼š
   - é€‰é¡¹1ï¼šç§¯æä¸»åŠ¨çš„é€‰æ‹©
   - é€‰é¡¹2ï¼šè°¨æ…ä¿å®ˆçš„é€‰æ‹©
   - é€‰é¡¹3ï¼šå†’é™©æˆ–æ„å¤–çš„é€‰æ‹©
6. æ¯ä¸ªé€‰é¡¹éƒ½è¦æœ‰ç®€çŸ­çš„å½±å“æç¤º
7. ä¸ºæ¯ä¸ªé€‰é¡¹æ·»åŠ æ ‡ç­¾åˆ†æï¼ŒåŒ…å«ä»¥ä¸‹äº”ä¸ªç»´åº¦ï¼ˆè¯·ä¸¥æ ¼ä½¿ç”¨æŒ‡å®šçš„å€¼ï¼Œä¸è¦æ··æ·†ï¼‰ï¼š
   - action_type: è¡ŒåŠ¨å€¾å‘ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼ˆactive/conservative/risky/diplomatic/aggressiveï¼‰
   - narrative_impact: å™äº‹å½±å“ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼ˆexploration/development/resolution/relationship/worldbuildingï¼‰
   - character_focus: è§’è‰²å‘å±•ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼ˆself_growth/relationship/world_interaction/skill_development/moral_choiceï¼‰
   - pacing_type: èŠ‚å¥æ§åˆ¶ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼ˆslow/medium/fastï¼‰
   - emotional_tone: æƒ…æ„Ÿè‰²å½©ï¼Œå¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼ˆpositive/neutral/dark/humorous/mysteriousï¼‰

ã€é‡è¦æ ¼å¼è¦æ±‚ã€‘ï¼š
- contentå­—æ®µåªåŒ…å«ç« èŠ‚æ­£æ–‡ï¼Œä»¥æ‚¬å¿µæˆ–æƒ…å¢ƒæå†™ç»“å°¾
- **ç¦æ­¢åœ¨contentä¸­åˆ—ä¸¾é€‰é¡¹å†…å®¹** (ä¾‹å¦‚"ä¸€ã€...äºŒã€...ä¸‰ã€...")
- **ç¦æ­¢åœ¨contentä¸­å±•ç¤ºé€‰é¡¹ç¼–å·æˆ–é€‰é¡¹æ–‡æœ¬**
- é€‰é¡¹å†…å®¹å…¨éƒ¨æ”¾åœ¨optionsæ•°ç»„ä¸­ï¼Œæ¯ä¸ªé€‰é¡¹æ˜¯ä¸€ä¸ªç‹¬ç«‹å¯¹è±¡
- contentç»“å°¾åº”è¯¥æ˜¯ç´§å¼ çš„æƒ…å¢ƒæˆ–æ‚¬å¿µï¼Œè®©è¯»è€…æœŸå¾…é€‰æ‹©ï¼Œä½†ä¸è¦å†™å‡ºå…·ä½“é€‰æ‹©

é”™è¯¯ç¤ºä¾‹ï¼š
content: "...ä»–åœä½è„šæ­¥ã€‚å‰è·¯ä¸‰å²”ï¼šä¸€ã€é—¯ç‹åºœï¼›äºŒã€ä¸Šå³¨çœ‰ï¼›ä¸‰ã€å…¥é’åŸã€‚ä»–è¯¥å¦‚ä½•é€‰æ‹©ï¼Ÿ"

æ­£ç¡®ç¤ºä¾‹ï¼š
content: "...ä»–åœä½è„šæ­¥ï¼Œä¸‰æ¡å±±è·¯åœ¨é›¨ä¸­è‹¥éšè‹¥ç°ï¼Œæ¯ä¸€æ¡éƒ½é€šå‘æœªçŸ¥çš„å‘½è¿ã€‚"
options: [{{text: "ç›´é—¯èœ€ç‹åºœ...", ...}}, {{text: "å…ˆä¸Šå³¨çœ‰åŒ»å®—...", ...}}, ...]

è¯·ç”¨JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«contentã€optionså­—æ®µã€‚
optionsæ•°ç»„ä¸­æ¯ä¸ªé€‰é¡¹åŒ…å«ï¼štextã€impact_hintã€tagså­—æ®µã€‚
tagså­—æ®µåŒ…å«ä¸Šè¿°äº”ä¸ªæ ‡ç­¾ç»´åº¦ã€‚"""

        return system_prompt, user_prompt

    async def generate_first_chapter_stream(
        self,
        world_setting: str,
        protagonist_info: str,
        genre: str = "wuxia"
    ) -> AsyncGenerator[str, None]:
        """ç”Ÿæˆç¬¬ä¸€ç« çš„æµå¼å†…å®¹"""
        try:
            logger.info("ğŸ¯ å¼€å§‹ç”Ÿæˆç¬¬ä¸€ç« æµå¼å†…å®¹")
            logger.info(f"ğŸ“š ç±»å‹: {genre}, ä¸–ç•Œè§‚é•¿åº¦: {len(world_setting)} å­—ç¬¦, ä¸»è§’ä¿¡æ¯é•¿åº¦: {len(protagonist_info)} å­—ç¬¦")

            # Step 1: ç”Ÿæˆç¬¬ä¸€ç« æ‘˜è¦
            logger.info("ğŸ“ Step 1: å¼€å§‹ç”Ÿæˆç« èŠ‚æ‘˜è¦")
            yield f"event: status\ndata: {json_dumps_chinese({'message': 'æ­£åœ¨ç”Ÿæˆç« èŠ‚æ‘˜è¦...'})}\n\n"

            system_prompt, user_prompt = self._build_first_chapter_summary_prompt(
                world_setting,
                protagonist_info,
                genre
            )

            logger.info(f"ğŸ”§ æ„å»ºæ‘˜è¦æç¤ºè¯å®Œæˆ, ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}, ç”¨æˆ·æç¤ºè¯é•¿åº¦: {len(user_prompt)}")

            summary_result = await kimi_service.generate_structured_output(
                model_class=ChapterSummary,
                user_prompt=user_prompt,
                system_prompt=system_prompt
            )

            if not summary_result["success"]:
                error_msg = f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {summary_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                logger.error(f"âŒ ç« èŠ‚æ‘˜è¦ç”Ÿæˆå¤±è´¥: {error_msg}")
                yield f"event: error\ndata: {json_dumps_chinese({'error': error_msg})}\n\n"
                return

            summary = ChapterSummary(**summary_result["data"])
            logger.info(f"âœ… Step 1 å®Œæˆ: ç« èŠ‚æ‘˜è¦ç”ŸæˆæˆåŠŸ")
            logger.info(f"ğŸ“– ç« èŠ‚æ ‡é¢˜: {summary.title}")
            logger.info(f"ğŸ­ å…³é”®å†²çª: {', '.join(summary.conflicts)}")
            logger.info(f"ğŸ“‹ å…³é”®äº‹ä»¶æ•°: {len(summary.key_events)}")

            # å‘é€æ‘˜è¦äº‹ä»¶
            yield f"event: summary\ndata: {json_dumps_chinese(summary.dict())}\n\n"

            # Step 2: ç”Ÿæˆç« èŠ‚æ­£æ–‡å’Œé€‰é¡¹
            logger.info("âœï¸  Step 2: å¼€å§‹ç”Ÿæˆç« èŠ‚æ­£æ–‡å’Œé€‰é¡¹")
            yield f"event: status\ndata: {json_dumps_chinese({'message': 'æ­£åœ¨ç”Ÿæˆç« èŠ‚æ­£æ–‡...'})}\n\n"

            context = ChapterContext(
                world_setting=world_setting,
                protagonist_info=protagonist_info,
                recent_chapters=[],
                chapter_summaries=[],
                selected_option=None
            )

            content_system_prompt, content_user_prompt = self._build_chapter_content_prompt(
                summary, context, genre
            )

            logger.info(f"ğŸ”§ æ„å»ºæ­£æ–‡æç¤ºè¯å®Œæˆ, ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(content_system_prompt)}, ç”¨æˆ·æç¤ºè¯é•¿åº¦: {len(content_user_prompt)}")

            # ä½¿ç”¨æµå¼è¾“å‡ºç”Ÿæˆæ­£æ–‡å’Œé€‰é¡¹
            content_char_count = 0

            async for stream_chunk in kimi_service.generate_streaming_output(
                model_class=ChapterFullContent,
                user_prompt=content_user_prompt,
                system_prompt=content_system_prompt
            ):
                # å°†StreamChunkè½¬æ¢ä¸ºSSEæ ¼å¼
                if stream_chunk.chunk_type == "content":
                    # åŸå§‹chunkï¼ˆJSONç‰‡æ®µï¼‰
                    chunk_text = stream_chunk.data['chunk']

                    # ç›´æ¥å‘é€åŸå§‹chunkï¼ˆå¾…é‡æ–°è®¾è®¡è§£æé€»è¾‘ï¼‰
                    if chunk_text:
                        content_char_count += len(chunk_text)
                        yield f"event: content\ndata: {json_dumps_chinese({'text': chunk_text})}\n\n"
                elif stream_chunk.chunk_type == "complete":
                    logger.info(f"âœ… Step 2 å®Œæˆ: ç« èŠ‚æ­£æ–‡å’Œé€‰é¡¹ç”ŸæˆæˆåŠŸ")
                    # ç»„è£…å®Œæ•´æ•°æ®
                    complete_data = stream_chunk.data['result']
                    complete_data['title'] = summary.title  # ä½¿ç”¨æ‘˜è¦é˜¶æ®µçš„title
                    complete_data['summary'] = summary.dict()

                    # ç»Ÿè®¡ä¿¡æ¯
                    content_length = len(complete_data.get('content', ''))
                    options_count = len(complete_data.get('options', []))
                    logger.info(f"ğŸ“Š æ­£æ–‡å­—ç¬¦æ•°: {content_length}, é€‰é¡¹æ•°é‡: {options_count}")

                    yield f"event: complete\ndata: {json_dumps_chinese(complete_data)}\n\n"
                elif stream_chunk.chunk_type == "error":
                    logger.error(f"âŒ æ­£æ–‡ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {stream_chunk.data}")
                    yield f"event: error\ndata: {json_dumps_chinese(stream_chunk.data)}\n\n"

        except Exception as e:
            logger.error(f"âŒ ç¬¬ä¸€ç« ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
            yield f"event: error\ndata: {json_dumps_chinese({'error': f'ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {str(e)}'})}\n\n"

    async def generate_next_chapter_stream(
        self,
        novel_id: int,
        selected_option_id: int,
        context: ChapterContext
    ) -> AsyncGenerator[str, None]:
        """ç”Ÿæˆåç»­ç« èŠ‚çš„æµå¼å†…å®¹"""
        try:
            logger.info(f"ğŸ¯ å¼€å§‹ç”Ÿæˆåç»­ç« èŠ‚æµå¼å†…å®¹")
            logger.info(f"ğŸ“š å°è¯´ID: {novel_id}, é€‰æ‹©çš„é€‰é¡¹ID: {selected_option_id}")
            logger.info(f"ğŸ“ å·²æœ‰ç« èŠ‚æ•°: {len(context.recent_chapters)}, å†å²æ‘˜è¦æ•°: {len(context.chapter_summaries)}")

            # Step 1: è·å–ç« èŠ‚ä¸Šä¸‹æ–‡
            logger.info("ğŸ“‹ Step 0: è·å–ç« èŠ‚ä¸Šä¸‹æ–‡å®Œæˆ")
            if context.selected_option:
                logger.info(f"ğŸ¯ ç”¨æˆ·é€‰æ‹©: {context.selected_option}")

            # Step 2: ç”Ÿæˆç« èŠ‚æ‘˜è¦
            logger.info("ğŸ“ Step 1: å¼€å§‹ç”Ÿæˆç« èŠ‚æ‘˜è¦")
            yield f"event: status\ndata: {json_dumps_chinese({'message': 'æ­£åœ¨ç”Ÿæˆç« èŠ‚æ‘˜è¦...'})}\n\n"

            system_prompt, user_prompt = self._build_next_chapter_summary_prompt(
                context, "wuxia"  # éœ€è¦ä»novelè·å–genreä¿¡æ¯
            )

            logger.info(f"ğŸ”§ æ„å»ºæ‘˜è¦æç¤ºè¯å®Œæˆ, ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)}, ç”¨æˆ·æç¤ºè¯é•¿åº¦: {len(user_prompt)}")

            summary_result = await kimi_service.generate_structured_output(
                model_class=ChapterSummary,
                user_prompt=user_prompt,
                system_prompt=system_prompt
            )

            if not summary_result["success"]:
                error_msg = f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {summary_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
                logger.error(f"âŒ åç»­ç« èŠ‚æ‘˜è¦ç”Ÿæˆå¤±è´¥: {error_msg}")
                yield f"event: error\ndata: {json_dumps_chinese({'error': error_msg})}\n\n"
                return

            summary = ChapterSummary(**summary_result["data"])
            logger.info(f"âœ… Step 1 å®Œæˆ: åç»­ç« èŠ‚æ‘˜è¦ç”ŸæˆæˆåŠŸ")
            logger.info(f"ğŸ“– ç« èŠ‚æ ‡é¢˜: {summary.title}")
            logger.info(f"ğŸ­ å…³é”®å†²çª: {', '.join(summary.conflicts)}")
            logger.info(f"ğŸ“‹ å…³é”®äº‹ä»¶æ•°: {len(summary.key_events)}")

            # å‘é€æ‘˜è¦äº‹ä»¶
            yield f"event: summary\ndata: {json_dumps_chinese(summary.dict())}\n\n"

            # Step 3: ç”Ÿæˆç« èŠ‚æ­£æ–‡å’Œé€‰é¡¹
            logger.info("âœï¸  Step 2: å¼€å§‹ç”Ÿæˆç« èŠ‚æ­£æ–‡å’Œé€‰é¡¹")
            yield f"event: status\ndata: {json_dumps_chinese({'message': 'æ­£åœ¨ç”Ÿæˆç« èŠ‚æ­£æ–‡...'})}\n\n"

            content_system_prompt, content_user_prompt = self._build_chapter_content_prompt(
                summary, context, "wuxia"
            )

            logger.info(f"ğŸ”§ æ„å»ºæ­£æ–‡æç¤ºè¯å®Œæˆ, ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(content_system_prompt)}, ç”¨æˆ·æç¤ºè¯é•¿åº¦: {len(content_user_prompt)}")

            # ä½¿ç”¨æµå¼è¾“å‡ºç”Ÿæˆæ­£æ–‡å’Œé€‰é¡¹
            async for stream_chunk in kimi_service.generate_streaming_output(
                model_class=ChapterFullContent,
                user_prompt=content_user_prompt,
                system_prompt=content_system_prompt
            ):
                # å°†StreamChunkè½¬æ¢ä¸ºSSEæ ¼å¼
                if stream_chunk.chunk_type == "content":
                    # åŸå§‹chunkï¼ˆJSONç‰‡æ®µï¼‰
                    chunk_text = stream_chunk.data['chunk']

                    # ç›´æ¥å‘é€åŸå§‹chunkï¼ˆå¾…é‡æ–°è®¾è®¡è§£æé€»è¾‘ï¼‰
                    if chunk_text:
                        yield f"event: content\ndata: {json_dumps_chinese({'text': chunk_text})}\n\n"
                elif stream_chunk.chunk_type == "complete":
                    logger.info(f"âœ… Step 2 å®Œæˆ: åç»­ç« èŠ‚æ­£æ–‡å’Œé€‰é¡¹ç”ŸæˆæˆåŠŸ")
                    # ç»„è£…å®Œæ•´æ•°æ®
                    complete_data = stream_chunk.data['result']
                    complete_data['title'] = summary.title  # ä½¿ç”¨æ‘˜è¦é˜¶æ®µçš„title
                    complete_data['summary'] = summary.dict()

                    # ç»Ÿè®¡ä¿¡æ¯
                    content_length = len(complete_data.get('content', ''))
                    options_count = len(complete_data.get('options', []))
                    logger.info(f"ğŸ“Š æ­£æ–‡å­—ç¬¦æ•°: {content_length}, é€‰é¡¹æ•°é‡: {options_count}")

                    yield f"event: complete\ndata: {json_dumps_chinese(complete_data)}\n\n"
                elif stream_chunk.chunk_type == "error":
                    logger.error(f"âŒ åç»­ç« èŠ‚æ­£æ–‡ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {stream_chunk.data}")
                    yield f"event: error\ndata: {json_dumps_chinese(stream_chunk.data)}\n\n"

        except Exception as e:
            logger.error(f"âŒ åç»­ç« èŠ‚ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
            yield f"event: error\ndata: {json_dumps_chinese({'error': f'ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {str(e)}'})}\n\n"

    async def generate_first_chapter_background(
        self,
        chapter_id: int,
        novel_id: int,
        world_setting: str,
        protagonist_info: str,
        genre: str
    ) -> None:
        """
        åå°ä»»åŠ¡ï¼šç”Ÿæˆç¬¬ä¸€ç« ï¼ˆå­˜å…¥Redisï¼‰

        æµç¨‹ï¼š
        1. ç”Ÿæˆæ‘˜è¦
        2. ç”Ÿæˆæ­£æ–‡ï¼ˆæµå¼ï¼‰â†’ æå–content â†’ å­˜Redis
        3. å®Œæˆåå­˜PostgreSQL

        æ³¨æ„: åå°ä»»åŠ¡åˆ›å»ºè‡ªå·±çš„æ•°æ®åº“session,é¿å…sessionè¢«æå‰å…³é—­
        """
        from app.db.database import async_session_maker

        session_id = StreamGenerationManager.generate_session_id()

        # åå°ä»»åŠ¡åˆ›å»ºè‡ªå·±çš„æ•°æ®åº“session
        async with async_session_maker() as db:
            async with managed_stream_generation(chapter_id, novel_id, session_id, db) as manager:
                try:
                    logger.info(f"ğŸ¯ åå°ä»»åŠ¡ï¼šå¼€å§‹ç”Ÿæˆç¬¬ä¸€ç«  {chapter_id}")

                    # Step 1: ç”Ÿæˆæ‘˜è¦
                    system_prompt, user_prompt = self._build_first_chapter_summary_prompt(
                        world_setting, protagonist_info, genre
                    )

                    summary_result = await kimi_service.generate_structured_output(
                        model_class=ChapterSummary,
                        user_prompt=user_prompt,
                        system_prompt=system_prompt
                    )

                    if not summary_result["success"]:
                        raise Exception(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {summary_result.get('error')}")

                    summary = ChapterSummary(**summary_result["data"])
                    logger.info(f"âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ: {summary.title}")

                    # åˆå§‹åŒ–Redisï¼ˆè®¾ç½®titleï¼‰
                    await manager.start_generation(summary.title)

                    # Step 2: ç”Ÿæˆæ­£æ–‡
                    context = ChapterContext(
                        world_setting=world_setting,
                        protagonist_info=protagonist_info,
                        recent_chapters=[],
                        chapter_summaries=[],
                        selected_option=None
                    )

                    content_system_prompt, content_user_prompt = self._build_chapter_content_prompt(
                        summary, context, genre
                    )

                    # ç´¯ç§¯JSONç”¨äºæå–
                    accumulated_json = ""
                    previous_content = ""  # è¿½è¸ªä¸Šä¸€æ¬¡çš„å†…å®¹,ç”¨äºè®¡ç®—å¢é‡

                    async for stream_chunk in kimi_service.generate_streaming_output(
                        model_class=ChapterFullContent,
                        user_prompt=content_user_prompt,
                        system_prompt=content_system_prompt
                    ):
                        if stream_chunk.chunk_type == "content":
                            # ç´¯ç§¯JSONç‰‡æ®µ
                            accumulated_json = stream_chunk.data['accumulated']

                            # æå–çº¯æ–‡æœ¬content(è¿™æ˜¯ç´¯ç§¯çš„å…¨éƒ¨å†…å®¹)
                            current_content = extract_content_from_json_fragment(accumulated_json)

                            # è®¡ç®—å¢é‡chunk
                            if current_content and len(current_content) > len(previous_content):
                                incremental_chunk = current_content[len(previous_content):]
                                await manager.append_chunk(incremental_chunk)
                                previous_content = current_content

                        elif stream_chunk.chunk_type == "complete":
                            # ç”Ÿæˆå®Œæˆ
                            result = stream_chunk.data['result']
                            final_content = result.get('content', '')
                            options = result.get('options', [])

                            logger.info(f"âœ… æ­£æ–‡ç”Ÿæˆå®Œæˆ: {len(final_content)} å­—ç¬¦, {len(options)} ä¸ªé€‰é¡¹")

                            # æœ€ç»ˆå†™å…¥PostgreSQLå¹¶æ¸…ç†Redis(åŒ…å«summary)
                            await manager.complete_generation(
                                final_content,
                                options,
                                summary=summary.summary  # ä¼ å…¥æ‘˜è¦æ–‡æœ¬
                            )

                        elif stream_chunk.chunk_type == "error":
                            raise Exception(f"ç”Ÿæˆé”™è¯¯: {stream_chunk.data}")

                    logger.info(f"ğŸ‰ ç¬¬ä¸€ç« ç”Ÿæˆå®Œæˆ: {chapter_id}")

                except Exception as e:
                    logger.error(f"âŒ ç¬¬ä¸€ç« åå°ç”Ÿæˆå¤±è´¥: {e}")
                    raise

    async def generate_next_chapter_background(
        self,
        chapter_id: int,
        novel_id: int,
        selected_option_id: int,
        genre: str
    ) -> None:
        """
        åå°ä»»åŠ¡ï¼šç”Ÿæˆåç»­ç« èŠ‚ï¼ˆå­˜å…¥Redisï¼‰

        æ³¨æ„: åå°ä»»åŠ¡åˆ›å»ºè‡ªå·±çš„æ•°æ®åº“session,é¿å…sessionè¢«æå‰å…³é—­
        """
        from app.db.database import async_session_maker

        session_id = StreamGenerationManager.generate_session_id()

        # åå°ä»»åŠ¡åˆ›å»ºè‡ªå·±çš„æ•°æ®åº“session
        async with async_session_maker() as db:
            async with managed_stream_generation(chapter_id, novel_id, session_id, db) as manager:
                try:
                    logger.info(f"ğŸ¯ åå°ä»»åŠ¡ï¼šå¼€å§‹ç”Ÿæˆåç»­ç« èŠ‚ {chapter_id}")

                    # æ„å»ºä¸Šä¸‹æ–‡ï¼ˆçœç•¥è¯¦ç»†ä»£ç ï¼Œä¸generate_next_chapter_streamç±»ä¼¼ï¼‰
                    chapter_service = ChapterService(db)
                    novel_service = NovelService(db)

                    # è·å–å°è¯´ä¿¡æ¯å’Œç« èŠ‚å†å²
                    novel = await novel_service.get_by_id(novel_id)
                    chapters = await chapter_service.get_chapters_by_novel(novel_id)

                    # æ„å»ºä¸Šä¸‹æ–‡
                    recent_chapters = [
                        {
                            "chapter_number": ch.chapter_number,
                            "title": ch.title,
                            "summary": getattr(ch, 'summary', ''),
                            "content": ch.content[:500] if ch.content else ''
                        }
                        for ch in chapters[-3:] if ch.status == ChapterStatus.COMPLETED
                    ]

                    context = ChapterContext(
                        world_setting=novel.background_setting or "",
                        protagonist_info=novel.character_setting or "",
                        recent_chapters=recent_chapters,
                        chapter_summaries=[],
                        selected_option=None  # TODO: è·å–é€‰é¡¹ä¿¡æ¯
                    )

                    # Step 1: ç”Ÿæˆæ‘˜è¦
                    system_prompt, user_prompt = self._build_next_chapter_summary_prompt(context, genre)

                    summary_result = await kimi_service.generate_structured_output(
                        model_class=ChapterSummary,
                        user_prompt=user_prompt,
                        system_prompt=system_prompt
                    )

                    if not summary_result["success"]:
                        raise Exception(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {summary_result.get('error')}")

                    summary = ChapterSummary(**summary_result["data"])
                    logger.info(f"âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ: {summary.title}")

                    await manager.start_generation(summary.title)

                    # Step 2: ç”Ÿæˆæ­£æ–‡
                    content_system_prompt, content_user_prompt = self._build_chapter_content_prompt(
                        summary, context, genre
                    )

                    accumulated_json = ""
                    previous_content = ""  # è¿½è¸ªä¸Šä¸€æ¬¡çš„å†…å®¹,ç”¨äºè®¡ç®—å¢é‡

                    async for stream_chunk in kimi_service.generate_streaming_output(
                        model_class=ChapterFullContent,
                        user_prompt=content_user_prompt,
                        system_prompt=content_system_prompt
                    ):
                        if stream_chunk.chunk_type == "content":
                            accumulated_json = stream_chunk.data['accumulated']
                            current_content = extract_content_from_json_fragment(accumulated_json)

                            # è®¡ç®—å¢é‡chunk
                            if current_content and len(current_content) > len(previous_content):
                                incremental_chunk = current_content[len(previous_content):]
                                await manager.append_chunk(incremental_chunk)
                                previous_content = current_content

                        elif stream_chunk.chunk_type == "complete":
                            result = stream_chunk.data['result']
                            final_content = result.get('content', '')
                            options = result.get('options', [])

                            # æœ€ç»ˆå†™å…¥PostgreSQLå¹¶æ¸…ç†Redis(åŒ…å«summary)
                            await manager.complete_generation(
                                final_content,
                                options,
                                summary=summary.summary  # ä¼ å…¥æ‘˜è¦æ–‡æœ¬
                            )

                        elif stream_chunk.chunk_type == "error":
                            raise Exception(f"ç”Ÿæˆé”™è¯¯: {stream_chunk.data}")

                    logger.info(f"ğŸ‰ åç»­ç« èŠ‚ç”Ÿæˆå®Œæˆ: {chapter_id}")

                except Exception as e:
                    logger.error(f"âŒ åç»­ç« èŠ‚åå°ç”Ÿæˆå¤±è´¥: {e}")
                    raise


# å…¨å±€ç« èŠ‚ç”ŸæˆæœåŠ¡å®ä¾‹
chapter_generator = ChapterGeneratorService()